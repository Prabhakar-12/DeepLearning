{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37c21b91add6bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3152/1047917041.py:4: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  s=X.storage()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X=torch.tensor([1,2,3,4])\n",
    "print(torch.is_tensor(X))\n",
    "s=X.storage()\n",
    "print(torch.is_storage(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe676756d07518f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn(1,2,3,4)\n",
    "#Gives the Total Elements Present in  the Tensor... like If the matrix has size (2,3) give the Total Elements as 5\n",
    "torch.numel(a)\n",
    "a=torch.randn(2,3,4)\n",
    "torch.numel(a)\n",
    "b=torch.randn(2,3,4,5)\n",
    "torch.numel(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae4fc2a-d36b-44bd-99f5-1e8cf2f3e40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842f0992-1176-4330-9dd1-369d22290e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class Neuron:\n",
    "    def __init__(self,weights,bais):\n",
    "        self.weights=weights\n",
    "        self.bais=bais\n",
    "    def Forward(self,inputs):\n",
    "        weighted_sum=0\n",
    "        for i in range(len(self.weights)):\n",
    "            weighted_sum+=self.weights[i]*inputs[i]\n",
    "\n",
    "        output=weighted_sum+self.bais\n",
    "        if output>=0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "#Hidden Layer \n",
    "Hidden_Layer1_Neuron1=Neuron(weights=[2,3],bais=3)\n",
    "inputs=[3,4]\n",
    "poioioioio\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccddeec6-5a11-408a-8ba3-f5043196c556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [5, 9] | Output: 1\n",
      "Inputs: [2, -14] | Output: 0\n"
     ]
    }
   ],
   "source": [
    "# A simple neuron model\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Calculate the weighted sum of inputs\n",
    "        weighted_sum = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            weighted_sum += self.weights[i] * inputs[i]\n",
    "\n",
    "        # Add the bias\n",
    "        output = weighted_sum + self.bias\n",
    "        \n",
    "        # Apply an activation function (here we use a simple step function for clarity)\n",
    "        if output >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# Example usage\n",
    "# Define the weights and bias for the neuron\n",
    "# Imagine we're trying to predict if a student passes a test based on\n",
    "# hours studied (input 1) and attendance rate (input 2)\n",
    "# Weight 1 (0.5) gives more importance to hours studied, Weight 2 (0.3) to attendance.\n",
    "# A bias of -2 means the student needs a certain minimum \"score\" to pass.\n",
    "neuron_weights = [0.5, 0.3]\n",
    "neuron_bias = -2.0\n",
    "\n",
    "# Create an instance of the Neuron\n",
    "my_neuron = Neuron(neuron_weights, neuron_bias)\n",
    "\n",
    "# Example 1: High hours studied (5) and high attendance (9)\n",
    "input_data_1 = [5, 9]\n",
    "output_1 = my_neuron.forward(input_data_1)\n",
    "print(f\"Inputs: {input_data_1} | Output: {output_1}\") # Output will be 1 (Pass)\n",
    "\n",
    "# Example 2: Low hours studied (2) and low attendance (4)\n",
    "input_data_2 = [2, -14]\n",
    "output_2 = my_neuron.forward(input_data_2)\n",
    "print(f\"Inputs: {input_data_2} | Output: {output_2}\") # Output will be 0 (Fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f52e6e2-81f1-48b4-85da-57a969fd0947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [5 9] | Hidden Layer Outputs: [1 1]\n",
      "Final Output of the network: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# A simple neuron class using NumPy for efficiency\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = bias\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Calculate the weighted sum using a dot product (more efficient)\n",
    "        weighted_sum = np.dot(self.weights, inputs) + self.bias\n",
    "        \n",
    "        # Apply a simple step function as the activation\n",
    "        if weighted_sum >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# --- Building the Multi-Layer Network ---\n",
    "\n",
    "# --- Hidden Layer ---\n",
    "# Let's create two neurons for our hidden layer\n",
    "# These neurons will process the initial inputs (hours studied, attendance)\n",
    "# Neuron 1 focuses on one aspect (e.g., studying habits)\n",
    "hidden_neuron_1 = Neuron(weights=[0.5, 0.3], bias=-2.0)\n",
    "# Neuron 2 focuses on another aspect (e.g., participation and engagement)\n",
    "hidden_neuron_2 = Neuron(weights=[0.6, 0.4], bias=-3.0)\n",
    "\n",
    "# Example 1: High hours studied (5) and high attendance (9)\n",
    "input_data = np.array([5, 9])\n",
    "\n",
    "# Calculate the output of each neuron in the hidden layer\n",
    "# These outputs will be the new inputs for the next layer\n",
    "hidden_output_1 = hidden_neuron_1.forward(input_data)\n",
    "hidden_output_2 = hidden_neuron_2.forward(input_data)\n",
    "\n",
    "# Combine the outputs into a new input vector for the next layer\n",
    "hidden_layer_output = np.array([hidden_output_1, hidden_output_2])\n",
    "print(f\"Input: {input_data} | Hidden Layer Outputs: {hidden_layer_output}\")\n",
    "\n",
    "# --- Output Layer ---\n",
    "# Now, let's create a final output neuron that takes the hidden layer's outputs as its input\n",
    "# The weights here decide how much importance the network places on the outputs of the hidden neurons.\n",
    "# This neuron predicts the final outcome (Pass or Fail)\n",
    "output_neuron = Neuron(weights=[0.7, 0.8], bias=-1.0)\n",
    "final_output = output_neuron.forward(hidden_layer_output)\n",
    "print(f\"Final Output of the network: {final_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f077a85e-187e-45ac-947c-d93b3ff39332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "59\n",
      "The Hidden Layer 1 Output is  [1 1]\n",
      "14\n",
      "17\n",
      "The Hidden Layer 2 Output is  [1 1]\n",
      "11\n",
      "The Final Neuron output is  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class Neuron:\n",
    "    def __init__(self,weights,bais):\n",
    "        self.weights=np.array(weights)\n",
    "        self.bais=bais\n",
    "    def Forward(self,inputs):\n",
    "        weighted_Sum=np.dot(self.weights,inputs)+self.bais\n",
    "        print(weighted_Sum)\n",
    "        if weighted_Sum>=0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "##Building the Hidden Layers\n",
    "#First Hidden Layer\n",
    "Hidden_Layer1_neuron_1=Neuron(weights=[3,4],bais=5)\n",
    "Hidden_Layer1_neuron_2=Neuron(weights=[4,6],bais=3)\n",
    "inputs=[5,6]\n",
    "Neuron_1_Output=Hidden_Layer1_neuron_1.Forward(inputs)\n",
    "Neuron_2_Output=Hidden_Layer1_neuron_2.Forward(inputs)\n",
    "Hidden_Layer1_Output=np.array([Neuron_1_Output,Neuron_2_Output])\n",
    "print(\"The Hidden Layer 1 Output is \",Hidden_Layer1_Output)\n",
    "#Second Hidden Layer\n",
    "Hidden_Layer2_Neuron_1=Neuron(weights=[5,6],bais=3)\n",
    "Hidden_Layer2_Neuron_2=Neuron(weights=[6,7],bais=4)\n",
    "Neuron_1_Output=Hidden_Layer2_Neuron_1.Forward(Hidden_Layer1_Output)\n",
    "Neuron_2_Output=Hidden_Layer2_Neuron_2.Forward(Hidden_Layer1_Output)\n",
    "Hidden_Layer2_Output=np.array([Neuron_1_Output,Neuron_2_Output])\n",
    "print(\"The Hidden Layer 2 Output is \",Hidden_Layer2_Output)\n",
    "#Final Output is \n",
    "FinalNeuron=Neuron(weights=[5,4],bais=2)\n",
    "FinalOutput=FinalNeuron.Forward(Hidden_Layer2_Output)\n",
    "print(\"The Final Neuron output is \",FinalOutput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f113be57-921e-425b-b936-e11992815bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hidden Layer1 Output is  [1 1]\n",
      "The Second Hidden Layer output is  [1 0]\n",
      "The Final Output is  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class Neuron:\n",
    "    def __init__(self,weights,bais):\n",
    "        self.weights=np.array(weights)\n",
    "        self.bais=bais\n",
    "    def Forward(self,inputs):\n",
    "        weighted_sum=np.dot(self.weights,inputs)+self.bais\n",
    "        if weighted_sum>=0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "##Building the Hidden Layers\n",
    "#Hidden Layer 1\n",
    "Hidden_Layer1_Neuron_1=Neuron(weights=[4,5],bais=3)\n",
    "Hidden_Layer1_Neuron_2=Neuron(weights=[4,2],bais=2)\n",
    "inputs=[3,4]\n",
    "HD1_Neuron_1_Output=Hidden_Layer1_Neuron_1.Forward(inputs)\n",
    "HD1_Neuron_2_Output=Hidden_Layer1_Neuron_2.Forward(inputs)\n",
    "Hidden_Layer1_Output=np.array([HD1_Neuron_1_Output,HD1_Neuron_2_Output])\n",
    "print(\"The Hidden Layer1 Output is \",Hidden_Layer1_Output)\n",
    "#Hidden Layer 2\n",
    "Hidden_Layer2_Neuron_1=Neuron(weights=[3,4],bais=-3)\n",
    "Hidden_Layer2_Neuron_2=Neuron(weights=[-2,3],bais=-3)\n",
    "HD2_Neuron_1_Output=Hidden_Layer2_Neuron_1.Forward(Hidden_Layer1_Output)\n",
    "HD2_Neuron_2_Output=Hidden_Layer2_Neuron_2.Forward(Hidden_Layer1_Output)\n",
    "Hidden_Layer2_Output=np.array([HD2_Neuron_1_Output,HD2_Neuron_2_Output])\n",
    "print(\"The Second Hidden Layer output is \",Hidden_Layer2_Output)\n",
    "#Final Output\n",
    "FinalNeuron=Neuron(weights=[4,-5],bais=-3)\n",
    "Final_Output=FinalNeuron.Forward(Hidden_Layer2_Output)\n",
    "print(\"The Final Output is \",Final_Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59c76045-aa7d-4030-af05-3364ada13313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output BEFORE backpropagation: 0.9999938558205577\n",
      "Output AFTER backpropagation: 0.9999938558205577\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# activation + derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias, lr=0.1):\n",
    "        self.weights = np.array(weights, dtype=float)\n",
    "        self.bias = float(bias)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = np.array(inputs, dtype=float)\n",
    "        self.weighted_sum = np.dot(self.weights, self.inputs) + self.bias\n",
    "        self.output = sigmoid(self.weighted_sum)                                                                     \n",
    "        return self.output\n",
    "\n",
    "    def backward(self, dloss_dout):\n",
    "        d_out_d_sum = sigmoid_derivative(self.output)\n",
    "        dloss_dsum = dloss_dout * d_out_d_sum\n",
    "        dloss_dweights = dloss_dsum * self.inputs\n",
    "        dloss_dbias = dloss_dsum\n",
    "        dloss_dinputs = dloss_dsum * self.weights\n",
    "        # update params\n",
    "        self.weights -= self.lr * dloss_dweights\n",
    "        self.bias -= self.lr * dloss_dbias\n",
    "        return dloss_dinputs\n",
    "\n",
    "# create network with some chosen values\n",
    "Hidden_Layer_1 = Neuron(weights=[5, -2], bias=1, lr=0.1)\n",
    "Hidden_Layer_2 = Neuron(weights=[-3, 8], bias=-3, lr=0.1)\n",
    "Output_Neuron = Neuron(weights=[7, -9], bias=5, lr=0.1)\n",
    "\n",
    "inputs = np.array([1, -5])  # sample input\n",
    "target = 1.0                   # desired output\n",
    "\n",
    "# ---- Forward pass (before training) ----\n",
    "h1_out = Hidden_Layer_1.forward(inputs)\n",
    "h2_out = Hidden_Layer_2.forward(inputs)\n",
    "hidden_outs = np.array([h1_out, h2_out])\n",
    "final_out = Output_Neuron.forward(hidden_outs)\n",
    "\n",
    "print(\"Output BEFORE backpropagation:\", final_out)\n",
    "\n",
    "# ---- Compute loss gradient and backprop ----\n",
    "dloss_dfinal = -(target - final_out)  # dL/dOut for output neuron\n",
    "dloss_dhidden = Output_Neuron.backward(dloss_dfinal)\n",
    "Hidden_Layer_1.backward(dloss_dhidden[0])\n",
    "Hidden_Layer_2.backward(dloss_dhidden[1])\n",
    "\n",
    "# ---- Forward pass (after weight update) ----\n",
    "h1_out = Hidden_Layer_1.forward(inputs)\n",
    "h2_out = Hidden_Layer_2.forward(inputs)\n",
    "hidden_outs = np.array([h1_out, h2_out])\n",
    "final_out_after = Output_Neuron.forward(hidden_outs)\n",
    "\n",
    "print(\"Output AFTER backpropagation:\", final_out_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb16f71a-5ad5-4d17-a865-1d61418623d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hidden Layer 1 output is  [0 1]\n",
      "The Hidden Layer 2 output is  [1 0]\n",
      "The Final Output is  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class Neuron:\n",
    "    def __init__(self,weights,bais):\n",
    "        self.weights=np.array(weights)\n",
    "        self.bais=bais\n",
    "    def Forward(self,inputs):\n",
    "        weighted_sum=np.dot(self.weights,inputs)+self.bais\n",
    "        if weighted_sum>=0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "##Building the Hidden Layers\n",
    "#Hidden Layer one\n",
    "Hidden_Layer_1_Neuron_1=Neuron(weights=[2,-4],bais=4)\n",
    "Hidden_Layer_1_Neuron_2=Neuron(weights=[4,5],bais=3)\n",
    "inputs=np.array([-4,5])\n",
    "HL1_Neuron_Output1=Hidden_Layer_1_Neuron_1.Forward(inputs)\n",
    "HL1_Neuron_Output2=Hidden_Layer_1_Neuron_2.Forward(inputs)\n",
    "Hidden_Layer_Output=np.array([HL1_Neuron_Output1,HL1_Neuron_Output2])\n",
    "print(\"The Hidden Layer 1 output is \",Hidden_Layer_Output)\n",
    "\n",
    "#Hidden Layer 2\n",
    "Hidden_Layer_2_Neuron_1=Neuron(weights=[2,-3],bais=3)\n",
    "Hidden_Layer_2_Neuron_2=Neuron(weights=[4,-5],bais=2)\n",
    "\n",
    "HL2_Neuron_Output1=Hidden_Layer_2_Neuron_1.Forward(Hidden_Layer_Output)\n",
    "HL2_Neuron_Output2=Hidden_Layer_2_Neuron_2.Forward(Hidden_Layer_Output)\n",
    "Hidden_Layer_2_Outputs=np.array([HL2_Neuron_Output1,HL2_Neuron_Output2])\n",
    "print(\"The Hidden Layer 2 output is \",Hidden_Layer_2_Outputs)\n",
    "#Final Neuron\n",
    "FinalNeuron=Neuron(weights=[3,4],bais=2)\n",
    "FinalOutput=FinalNeuron.Forward(Hidden_Layer_2_Outputs)\n",
    "print(\"The Final Output is \",FinalOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5a95bfc-c046-41c7-a957-2fbbbce767ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Input_1', 'Input_2', 'Target'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "class Neuron:\n",
    "    def __init__(self,weights,bais):\n",
    "        self.weights=np.array(weights)\n",
    "        self.bais=bais\n",
    "    def Forward(self,inputs):\n",
    "        self.inputs=inputs\n",
    "        weighted_sum=np.dot(self.weights,self.inputs)+self.bais\n",
    "        if weighted_sum>0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "Data=pd.read_csv(\"XORGateDataSet.csv\")\n",
    "Data.columns      \n",
    "##Building theNeuron Network\n",
    "#Hidden Layer 1\n",
    "# Hidden_Layer1_Neuron1=Neuron(weights=[3,4,4,5],bais=3)\n",
    "# Hidden_Layer1_Neuron2=Neuron(weights=[4,5,6,7],bais=2)\n",
    "# inputs=Data.iloc[:,:2]\n",
    "# Target=Data.iloc[:,-1]\n",
    "# HD1_Neuorn1_Output=Hidden_Layer1_Neuron1.Forward(inputs)\n",
    "# HD1_Neuron2_Output=Hidden_Layer1_Neuron2.Forward(inputs)\n",
    "# HD1_Outputs=np.array([HD1_Neuron1_Output,HD1_Neuron2_Output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d4d94dd-5d16-4a51-94ab-4a7a62255d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000, Total Squared Error: 0.5724\n",
      "Epoch: 2000, Total Squared Error: 0.5155\n",
      "Epoch: 3000, Total Squared Error: 0.5085\n",
      "Epoch: 4000, Total Squared Error: 0.5060\n",
      "Epoch: 5000, Total Squared Error: 0.5048\n",
      "Epoch: 6000, Total Squared Error: 0.5040\n",
      "Epoch: 7000, Total Squared Error: 0.5036\n",
      "Epoch: 8000, Total Squared Error: 0.5032\n",
      "Epoch: 9000, Total Squared Error: 0.5029\n",
      "Epoch: 10000, Total Squared Error: 0.5027\n",
      "\n",
      "Final predictions after training:\n",
      "Inputs: [0. 0.], Target: 0.0, Prediction: 0.0144\n",
      "Inputs: [0. 1.], Target: 1.0, Prediction: 0.9816\n",
      "Inputs: [1. 0.], Target: 1.0, Prediction: 0.4752\n",
      "Inputs: [1. 1.], Target: 0.0, Prediction: 0.4762\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Activation functions and their derivatives\n",
    "# The sigmoid function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# 2. The Neuron Class\n",
    "# This class represents a single neuron in the network.\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias, lr=0.5):\n",
    "        self.weights = np.array(weights, dtype=float)\n",
    "        self.bias = float(bias)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = np.array(inputs, dtype=float)\n",
    "        self.weighted_sum = np.dot(self.weights, self.inputs) + self.bias\n",
    "        self.output = sigmoid(self.weighted_sum)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, dloss_dout):\n",
    "        d_out_d_sum = sigmoid_derivative(self.output)\n",
    "        dloss_dsum = dloss_dout * d_out_d_sum\n",
    "        dloss_dweights = dloss_dsum * self.inputs\n",
    "        dloss_dbias = dloss_dsum\n",
    "        dloss_dinputs = dloss_dsum * self.weights\n",
    "        \n",
    "        # Update the neuron's parameters\n",
    "        self.weights -= self.lr * dloss_dweights\n",
    "        self.bias -= self.lr * dloss_dbias\n",
    "        \n",
    "        return dloss_dinputs\n",
    "\n",
    "# 3. Network Architecture and Data\n",
    "# Define the dataset\n",
    "# This is a small XOR gate dataset.\n",
    "XOR_inputs = np.array([[0.0, 0.0],\n",
    "                       [0.0, 1.0],\n",
    "                       [1.0, 0.0],\n",
    "                       [1.0, 1.0]])\n",
    "\n",
    "XOR_targets = np.array([0.0, 1.0, 1.0, 0.0])\n",
    "Data=pd.read_csv(\"XORGateDataSet.csv\")\n",
    "XOR_inputs1=Data[['Input_1','Input_2']]\n",
    "\n",
    "XOR_targets1=Data['Target']\n",
    "# Create the neurons for the network\n",
    "Hidden_Layer_1 = Neuron(weights=[0.5, -0.2], bias=0.1, lr=0.5)\n",
    "Hidden_Layer_2 = Neuron(weights=[0.3, 0.8], bias=-0.3, lr=0.5)\n",
    "Output_Neuron = Neuron(weights=[-0.7, 0.9], bias=0.05, lr=0.5)\n",
    "\n",
    "# Number of epochs for training\n",
    "epochs = 10000\n",
    "\n",
    "# 4. Training Loop\n",
    "# The core training process that combines forward and backpropagation.\n",
    "for epoch in range(epochs):\n",
    "    # Iterate through each data sample in the dataset\n",
    "    for i in range(len(XOR_inputs)):\n",
    "        inputs = XOR_inputs[i]\n",
    "        target = XOR_targets[i]\n",
    "\n",
    "        # ---- Forward Pass ----\n",
    "        # The data flows from the input layer through the hidden layer to the output layer.\n",
    "        h1_out = Hidden_Layer_1.forward(inputs)\n",
    "        h2_out = Hidden_Layer_2.forward(inputs)\n",
    "        \n",
    "        hidden_outs = np.array([h1_out, h2_out])\n",
    "        final_out = Output_Neuron.forward(hidden_outs)\n",
    "\n",
    "        # ---- Backpropagation ----\n",
    "        # The error is propagated backward from the output layer to the hidden layer.\n",
    "        # dloss_dfinal is the derivative of the loss function (mean squared error)\n",
    "        dloss_dfinal = -(target - final_out)\n",
    "        \n",
    "        # Propagate the error back to the hidden layer neurons\n",
    "        dloss_dhidden = Output_Neuron.backward(dloss_dfinal)\n",
    "        \n",
    "        # Backpropagate the error from the hidden layer to the input layer\n",
    "        Hidden_Layer_1.backward(dloss_dhidden[0])\n",
    "        Hidden_Layer_2.backward(dloss_dhidden[1])\n",
    "\n",
    "    # Print the error every 1000 epochs to monitor progress\n",
    "    if (epoch + 1) % 1000 == 0:\n",
    "        # Re-run the forward pass for the entire dataset to check the total error\n",
    "        total_error = 0\n",
    "        for i in range(len(XOR_inputs)):\n",
    "            inputs = XOR_inputs[i]\n",
    "            target = XOR_targets[i]\n",
    "            \n",
    "            h1_out = Hidden_Layer_1.forward(inputs)\n",
    "            h2_out = Hidden_Layer_2.forward(inputs)\n",
    "            hidden_outs = np.array([h1_out, h2_out])\n",
    "            final_out = Output_Neuron.forward(hidden_outs)\n",
    "            \n",
    "            total_error += (target - final_out)**2\n",
    "        print(f\"Epoch: {epoch + 1}, Total Squared Error: {total_error:.4f}\")\n",
    "\n",
    "# 5. Final Predictions (After Training)\n",
    "print(\"\\nFinal predictions after training:\")\n",
    "for i in range(len(XOR_inputs)):\n",
    "    inputs = XOR_inputs[i]\n",
    "    target = XOR_targets[i]\n",
    "    \n",
    "    h1_out = Hidden_Layer_1.forward(inputs)\n",
    "    h2_out = Hidden_Layer_2.forward(inputs)\n",
    "    hidden_outs = np.array([h1_out, h2_out])\n",
    "    final_out = Output_Neuron.forward(hidden_outs)\n",
    "    \n",
    "    print(f\"Inputs: {inputs}, Target: {target}, Prediction: {final_out:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "552fd00e-8875-481c-b535-c357cf9a4b0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1182593868.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    impot torch\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "impot torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a90b21a-b18b-4303-ab73-0a42a1901bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try\n",
      "\u001b[31m   \u001b[0m zypper install python313-xyz, where xyz is the package\n",
      "\u001b[31m   \u001b[0m you are trying to install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-rpm packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3.13 -m venv path/to/venv.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-rpm packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use `pipx install xyz`, which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Install pipx via `zypper install python313-pipx` .\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1669a8b-4d0e-4e21-8920-10e275a146d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.2\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m pd\u001b[38;5;241m.\u001b[39m__version__\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install pandas\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)\n",
    "import pandas as pd\n",
    "pd.__version__\n",
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2946957-ff18-4857-8606-da8b8a75be71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0552ef97-33a5-4b21-b454-1902018384c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfcc956f-eb33-4254-9b59-990c6639b673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try\n",
      "\u001b[31m   \u001b[0m zypper install python313-xyz, where xyz is the package\n",
      "\u001b[31m   \u001b[0m you are trying to install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-rpm packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3.13 -m venv path/to/venv.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-rpm packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use `pipx install xyz`, which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Install pipx via `zypper install python313-pipx` .\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas matplotlib seaborn scikit-learn tensorflow torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2116586c-b59c-484c-8e48-f62c5bb9e0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
