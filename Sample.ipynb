{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b37c21b91add6bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3152/1047917041.py:4: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  s=X.storage()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X=torch.tensor([1,2,3,4])\n",
    "print(torch.is_tensor(X))\n",
    "s=X.storage()\n",
    "print(torch.is_storage(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbe676756d07518f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.randn(1,2,3,4)\n",
    "#Gives the Total Elements Present in  the Tensor... like If the matrix has size (2,3) give the Total Elements as 5\n",
    "torch.numel(a)\n",
    "a=torch.randn(2,3,4)\n",
    "torch.numel(a)\n",
    "b=torch.randn(2,3,4,5)\n",
    "torch.numel(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae4fc2a-d36b-44bd-99f5-1e8cf2f3e40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu126\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccddeec6-5a11-408a-8ba3-f5043196c556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [5, 9] | Output: 1\n",
      "Inputs: [2, -14] | Output: 0\n"
     ]
    }
   ],
   "source": [
    "# A simple neuron model\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Calculate the weighted sum of inputs\n",
    "        weighted_sum = 0\n",
    "        for i in range(len(self.weights)):\n",
    "            weighted_sum += self.weights[i] * inputs[i]\n",
    "\n",
    "        # Add the bias\n",
    "        output = weighted_sum + self.bias\n",
    "        \n",
    "        # Apply an activation function (here we use a simple step function for clarity)\n",
    "        if output >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# Example usage\n",
    "# Define the weights and bias for the neuron\n",
    "# Imagine we're trying to predict if a student passes a test based on\n",
    "# hours studied (input 1) and attendance rate (input 2)\n",
    "# Weight 1 (0.5) gives more importance to hours studied, Weight 2 (0.3) to attendance.\n",
    "# A bias of -2 means the student needs a certain minimum \"score\" to pass.\n",
    "neuron_weights = [0.5, 0.3]\n",
    "neuron_bias = -2.0\n",
    "\n",
    "# Create an instance of the Neuron\n",
    "my_neuron = Neuron(neuron_weights, neuron_bias)\n",
    "\n",
    "# Example 1: High hours studied (5) and high attendance (9)\n",
    "input_data_1 = [5, 9]\n",
    "output_1 = my_neuron.forward(input_data_1)\n",
    "print(f\"Inputs: {input_data_1} | Output: {output_1}\") # Output will be 1 (Pass)\n",
    "\n",
    "# Example 2: Low hours studied (2) and low attendance (4)\n",
    "input_data_2 = [2, -14]\n",
    "output_2 = my_neuron.forward(input_data_2)\n",
    "print(f\"Inputs: {input_data_2} | Output: {output_2}\") # Output will be 0 (Fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f52e6e2-81f1-48b4-85da-57a969fd0947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [5 9] | Hidden Layer Outputs: [1 1]\n",
      "Final Output of the network: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# A simple neuron class using NumPy for efficiency\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = np.array(weights)\n",
    "        self.bias = bias\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Calculate the weighted sum using a dot product (more efficient)\n",
    "        weighted_sum = np.dot(self.weights, inputs) + self.bias\n",
    "        \n",
    "        # Apply a simple step function as the activation\n",
    "        if weighted_sum >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "# --- Building the Multi-Layer Network ---\n",
    "\n",
    "# --- Hidden Layer ---\n",
    "# Let's create two neurons for our hidden layer\n",
    "# These neurons will process the initial inputs (hours studied, attendance)\n",
    "# Neuron 1 focuses on one aspect (e.g., studying habits)\n",
    "hidden_neuron_1 = Neuron(weights=[0.5, 0.3], bias=-2.0)\n",
    "# Neuron 2 focuses on another aspect (e.g., participation and engagement)\n",
    "hidden_neuron_2 = Neuron(weights=[0.6, 0.4], bias=-3.0)\n",
    "\n",
    "# Example 1: High hours studied (5) and high attendance (9)\n",
    "input_data = np.array([5, 9])\n",
    "\n",
    "# Calculate the output of each neuron in the hidden layer\n",
    "# These outputs will be the new inputs for the next layer\n",
    "hidden_output_1 = hidden_neuron_1.forward(input_data)\n",
    "hidden_output_2 = hidden_neuron_2.forward(input_data)\n",
    "\n",
    "# Combine the outputs into a new input vector for the next layer\n",
    "hidden_layer_output = np.array([hidden_output_1, hidden_output_2])\n",
    "print(f\"Input: {input_data} | Hidden Layer Outputs: {hidden_layer_output}\")\n",
    "\n",
    "# --- Output Layer ---\n",
    "# Now, let's create a final output neuron that takes the hidden layer's outputs as its input\n",
    "# The weights here decide how much importance the network places on the outputs of the hidden neurons.\n",
    "# This neuron predicts the final outcome (Pass or Fail)\n",
    "output_neuron = Neuron(weights=[0.7, 0.8], bias=-1.0)\n",
    "final_output = output_neuron.forward(hidden_layer_output)\n",
    "print(f\"Final Output of the network: {final_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f077a85e-187e-45ac-947c-d93b3ff39332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "59\n",
      "The Hidden Layer 1 Output is  [1 1]\n",
      "14\n",
      "17\n",
      "The Hidden Layer 2 Output is  [1 1]\n",
      "11\n",
      "The Final Neuron output is  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class Neuron:\n",
    "    def __init__(self,weights,bais):\n",
    "        self.weights=np.array(weights)\n",
    "        self.bais=bais\n",
    "    def Forward(self,inputs):\n",
    "        weighted_Sum=np.dot(self.weights,inputs)+self.bais\n",
    "        print(weighted_Sum)\n",
    "        if weighted_Sum>=0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "##Building the Hidden Layers\n",
    "#First Hidden Layer\n",
    "Hidden_Layer1_neuron_1=Neuron(weights=[3,4],bais=5)\n",
    "Hidden_Layer1_neuron_2=Neuron(weights=[4,6],bais=3)\n",
    "inputs=[5,6]\n",
    "Neuron_1_Output=Hidden_Layer1_neuron_1.Forward(inputs)\n",
    "Neuron_2_Output=Hidden_Layer1_neuron_2.Forward(inputs)\n",
    "Hidden_Layer1_Output=np.array([Neuron_1_Output,Neuron_2_Output])\n",
    "print(\"The Hidden Layer 1 Output is \",Hidden_Layer1_Output)\n",
    "#Second Hidden Layer\n",
    "Hidden_Layer2_Neuron_1=Neuron(weights=[5,6],bais=3)\n",
    "Hidden_Layer2_Neuron_2=Neuron(weights=[6,7],bais=4)\n",
    "Neuron_1_Output=Hidden_Layer2_Neuron_1.Forward(Hidden_Layer1_Output)\n",
    "Neuron_2_Output=Hidden_Layer2_Neuron_2.Forward(Hidden_Layer1_Output)\n",
    "Hidden_Layer2_Output=np.array([Neuron_1_Output,Neuron_2_Output])\n",
    "print(\"The Hidden Layer 2 Output is \",Hidden_Layer2_Output)\n",
    "#Final Output is \n",
    "FinalNeuron=Neuron(weights=[5,4],bais=2)\n",
    "FinalOutput=FinalNeuron.Forward(Hidden_Layer2_Output)\n",
    "print(\"The Final Neuron output is \",FinalOutput)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f113be57-921e-425b-b936-e11992815bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hidden Layer1 Output is  [1 1]\n",
      "The Second Hidden Layer output is  [1 0]\n",
      "The Final Output is  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class Neuron:\n",
    "    def __init__(self,weights,bais):\n",
    "        self.weights=np.array(weights)\n",
    "        self.bais=bais\n",
    "    def Forward(self,inputs):\n",
    "        weighted_sum=np.dot(self.weights,inputs)+self.bais\n",
    "        if weighted_sum>=0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "##Building the Hidden Layers\n",
    "#Hidden Layer 1\n",
    "Hidden_Layer1_Neuron_1=Neuron(weights=[4,5],bais=3)\n",
    "Hidden_Layer1_Neuron_2=Neuron(weights=[4,2],bais=2)\n",
    "inputs=[3,4]\n",
    "HD1_Neuron_1_Output=Hidden_Layer1_Neuron_1.Forward(inputs)\n",
    "HD1_Neuron_2_Output=Hidden_Layer1_Neuron_2.Forward(inputs)\n",
    "Hidden_Layer1_Output=np.array([HD1_Neuron_1_Output,HD1_Neuron_2_Output])\n",
    "print(\"The Hidden Layer1 Output is \",Hidden_Layer1_Output)\n",
    "#Hidden Layer 2\n",
    "Hidden_Layer2_Neuron_1=Neuron(weights=[3,4],bais=-3)\n",
    "Hidden_Layer2_Neuron_2=Neuron(weights=[-2,3],bais=-3)\n",
    "HD2_Neuron_1_Output=Hidden_Layer2_Neuron_1.Forward(Hidden_Layer1_Output)\n",
    "HD2_Neuron_2_Output=Hidden_Layer2_Neuron_2.Forward(Hidden_Layer1_Output)\n",
    "Hidden_Layer2_Output=np.array([HD2_Neuron_1_Output,HD2_Neuron_2_Output])\n",
    "print(\"The Second Hidden Layer output is \",Hidden_Layer2_Output)\n",
    "#Final Output\n",
    "FinalNeuron=Neuron(weights=[4,-5],bais=-3)\n",
    "Final_Output=FinalNeuron.Forward(Hidden_Layer2_Output)\n",
    "print(\"The Final Output is \",Final_Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59c76045-aa7d-4030-af05-3364ada13313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output BEFORE backpropagation: 0.5381997566506256\n",
      "Output AFTER backpropagation: 0.5653404376286888\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# activation + derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias, lr=0.1):\n",
    "        self.weights = np.array(weights, dtype=float)\n",
    "        self.bias = float(bias)\n",
    "        self.lr = lr\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = np.array(inputs, dtype=float)\n",
    "        self.weighted_sum = np.dot(self.weights, self.inputs) + self.bias\n",
    "        self.output = sigmoid(self.weighted_sum)                                                                     \n",
    "        return self.output\n",
    "\n",
    "    def backward(self, dloss_dout):\n",
    "        d_out_d_sum = sigmoid_derivative(self.output)\n",
    "        dloss_dsum = dloss_dout * d_out_d_sum\n",
    "        dloss_dweights = dloss_dsum * self.inputs\n",
    "        dloss_dbias = dloss_dsum\n",
    "        dloss_dinputs = dloss_dsum * self.weights\n",
    "        # update params\n",
    "        self.weights -= self.lr * dloss_dweights\n",
    "        self.bias -= self.lr * dloss_dbias\n",
    "        return dloss_dinputs\n",
    "\n",
    "# create network with some chosen values\n",
    "Hidden_Layer_1 = Neuron(weights=[0.5, -0.2], bias=0.1, lr=0.5)\n",
    "Hidden_Layer_2 = Neuron(weights=[0.3, 0.8], bias=-0.3, lr=0.5)\n",
    "Output_Neuron = Neuron(weights=[-0.7, 0.9], bias=0.05, lr=0.5)\n",
    "\n",
    "inputs = np.array([1.0, 0.5])  # sample input\n",
    "target = 1.0                   # desired output\n",
    "\n",
    "# ---- Forward pass (before training) ----\n",
    "h1_out = Hidden_Layer_1.forward(inputs)\n",
    "h2_out = Hidden_Layer_2.forward(inputs)\n",
    "hidden_outs = np.array([h1_out, h2_out])\n",
    "final_out = Output_Neuron.forward(hidden_outs)\n",
    "\n",
    "print(\"Output BEFORE backpropagation:\", final_out)\n",
    "\n",
    "# ---- Compute loss gradient and backprop ----\n",
    "dloss_dfinal = -(target - final_out)  # dL/dOut for output neuron\n",
    "dloss_dhidden = Output_Neuron.backward(dloss_dfinal)\n",
    "Hidden_Layer_1.backward(dloss_dhidden[0])\n",
    "Hidden_Layer_2.backward(dloss_dhidden[1])\n",
    "\n",
    "# ---- Forward pass (after weight update) ----\n",
    "h1_out = Hidden_Layer_1.forward(inputs)\n",
    "h2_out = Hidden_Layer_2.forward(inputs)\n",
    "hidden_outs = np.array([h1_out, h2_out])\n",
    "final_out_after = Output_Neuron.forward(hidden_outs)\n",
    "\n",
    "print(\"Output AFTER backpropagation:\", final_out_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb16f71a-5ad5-4d17-a865-1d61418623d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hidden Layer 1 output is  [0 1]\n",
      "The Hidden Layer 2 output is  [1 0]\n",
      "The Final Output is  1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "class Neuron:\n",
    "    def __init__(self,weights,bais):\n",
    "        self.weights=np.array(weights)\n",
    "        self.bais=bais\n",
    "    def Forward(self,inputs):\n",
    "        weighted_sum=np.dot(self.weights,inputs)+self.bais\n",
    "        if weighted_sum>=0:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "##Building the Hidden Layers\n",
    "#Hidden Layer one\n",
    "Hidden_Layer_1_Neuron_1=Neuron(weights=[2,-4],bais=4)\n",
    "Hidden_Layer_1_Neuron_2=Neuron(weights=[4,5],bais=3)\n",
    "inputs=np.array([-4,5])\n",
    "HL1_Neuron_Output1=Hidden_Layer_1_Neuron_1.Forward(inputs)\n",
    "HL1_Neuron_Output2=Hidden_Layer_1_Neuron_2.Forward(inputs)\n",
    "Hidden_Layer_Output=np.array([HL1_Neuron_Output1,HL1_Neuron_Output2])\n",
    "print(\"The Hidden Layer 1 output is \",Hidden_Layer_Output)\n",
    "\n",
    "#Hidden Layer 2\n",
    "Hidden_Layer_2_Neuron_1=Neuron(weights=[2,-3],bais=3)\n",
    "Hidden_Layer_2_Neuron_2=Neuron(weights=[4,-5],bais=2)\n",
    "\n",
    "HL2_Neuron_Output1=Hidden_Layer_2_Neuron_1.Forward(Hidden_Layer_Output)\n",
    "HL2_Neuron_Output2=Hidden_Layer_2_Neuron_2.Forward(Hidden_Layer_Output)\n",
    "Hidden_Layer_2_Outputs=np.array([HL2_Neuron_Output1,HL2_Neuron_Output2])\n",
    "print(\"The Hidden Layer 2 output is \",Hidden_Layer_2_Outputs)\n",
    "#Final Neuron\n",
    "FinalNeuron=Neuron(weights=[3,4],bais=2)\n",
    "FinalOutput=FinalNeuron.Forward(Hidden_Layer_2_Outputs)\n",
    "print(\"The Final Output is \",FinalOutput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
